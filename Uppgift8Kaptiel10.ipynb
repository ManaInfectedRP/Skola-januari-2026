{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2205060f",
   "metadata": {},
   "source": [
    "# Uppgift 8, Kapitel 10: Skapa en Chattbot med RAG\n",
    "\n",
    "## Uppgift\n",
    "Skapa en chattbot som svarar p√• fr√•gor utifr√•n ett dokument. Du ska anv√§nda RAG (Retrieval Augmented Generation) f√∂r att:\n",
    "1. L√§sa in ett PDF-dokument\n",
    "2. Dela upp dokumentet i chunks\n",
    "3. Skapa embeddings f√∂r varje chunk\n",
    "4. Implementera semantisk s√∂kning\n",
    "5. Generera svar utifr√•n relevant kontext\n",
    "\n",
    "Vi anv√§nder boken \"L√§r dig AI fr√•n grunden - Till√§mpad maskininl√§rning med Python\" som k√§lldokument."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77705d6b",
   "metadata": {},
   "source": [
    "## 1. Installation och Import av bibliotek"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bbb6222",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Installera n√∂dv√§ndiga paket\n",
    "# pip install google-genai pypdf numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2ff3160c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from google import genai\n",
    "from pypdf import PdfReader\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6b3d871",
   "metadata": {},
   "source": [
    "## 2. St√§ll in API-nyckel och klient\n",
    "\n",
    "**VIKTIGT:** Du beh√∂ver skapa en egen API-nyckel fr√•n https://aistudio.google.com/\n",
    "- G√• till \"Create API key\"\n",
    "- Du beh√∂ver registrera ett bankkort f√∂r gratis provperiod\n",
    "- DELA ALDRIG din API-nyckel offentligt!\n",
    "\n",
    "F√∂r s√§kerhet kan du anv√§nda milj√∂variabler: `api_key = os.getenv('API_KEY')`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2d94969b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ers√§tt denna med din egen API-nyckel\n",
    "api_key = os.getenv('GOOGLE_API_KEY')  # H√§mta fr√•n milj√∂variabler f√∂r s√§kerhet\n",
    "if not api_key:\n",
    "    api_key = 'AIzaSyBgeO03ptyd1Lp6c5Y8VYPz4cwb1IAnhBU'  # Eller ange manuellt\n",
    "client = genai.Client(api_key=api_key)\n",
    "model = \"gemini-2.0-flash\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "954e2bb3",
   "metadata": {},
   "source": [
    "## 3. L√§s in PDF-dokumentet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "735817ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úì PDF inl√§st framg√•ngsrikt\n",
      "  Total textl√§ngd: 443311 tecken\n",
      "  Antal sidor: 348\n"
     ]
    }
   ],
   "source": [
    "# L√§s PDF-filen\n",
    "pdf_path = \"publicerad_bok 4.pdf\"\n",
    "\n",
    "try:\n",
    "    reader = PdfReader(pdf_path)\n",
    "    \n",
    "    # Extrahera all text fr√•n PDF:en\n",
    "    text = \"\"\n",
    "    for i, page in enumerate(reader.pages):\n",
    "        try:\n",
    "            page_text = page.extract_text()\n",
    "            if page_text:\n",
    "                text += page_text\n",
    "        except Exception as e:\n",
    "            print(f\"Varning: Kunde inte extrahera text fr√•n sida {i+1}: {e}\")\n",
    "            continue\n",
    "    \n",
    "    if not text:\n",
    "        raise ValueError(\"Ingen text kunde extraheras fr√•n PDF:en. PDF:en kan vara krypterad eller skadad.\")\n",
    "    \n",
    "    print(f\"‚úì PDF inl√§st framg√•ngsrikt\")\n",
    "    print(f\"  Total textl√§ngd: {len(text)} tecken\")\n",
    "    print(f\"  Antal sidor: {len(reader.pages)}\")\n",
    "    \n",
    "except FileNotFoundError:\n",
    "    print(f\"‚ùå Fel: Filen '{pdf_path}' hittades inte\")\n",
    "    print(f\"   Kontrollera att filen finns i samma mapp som notebooken\")\n",
    "    raise\n",
    "except Exception as e:\n",
    "    print(f\"‚ùå Fel vid l√§sning av PDF: {e}\")\n",
    "    raise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1b0323a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "L√ÑR DIG AI FR√ÖN\n",
      "GRUNDEN - TILL√ÑMPAD\n",
      "MASKININL√ÑRNING MED\n",
      "PYTHON\n",
      "Antonio Prgomet\n",
      "Terese Johnson\n",
      "Amanda Solberg\n",
      "Linus Rundberg StreuliDetta verk √§r skyddat av upphovsr√§ttslagen.\n",
      "Den som bryter mot upphovsr√§ttslagen kan √•talas av allm√§n √•klagare och d√∂mas till b√∂-\n",
      "ter eller f√§ngelse i upp till tv√• √•r samt bli skyldig att erl√§gga ers√§ttning till upphovsman\n",
      "eller r√§ttsinnehavare.\n",
      "¬© Pedagogicus PublishingInneh√•llsf√∂rteckning\n",
      "F√∂rord 7\n",
      "Bokens hemsida . . . . . . . . . . . . . . . . . . . . . . . . . . . \n"
     ]
    }
   ],
   "source": [
    "# Visa ett utdrag fr√•n dokumentet\n",
    "print(text[0:500])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f0b0f96",
   "metadata": {},
   "source": [
    "## 4. Chunking - Dela upp texten i mindre delar\n",
    "\n",
    "Vi anv√§nder **fixed-length chunking** med √∂verlappning f√∂r att s√§kerst√§lla att viktiga koncept inte splittras mellan chunks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c12c0f0a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Antal chunks skapade: 555\n"
     ]
    }
   ],
   "source": [
    "def create_chunks(text, chunk_size=1000, overlap=200):\n",
    "    \"\"\"\n",
    "    Dela upp text i chunks med √∂verlappning.\n",
    "    \n",
    "    Args:\n",
    "        text: Texten att dela upp\n",
    "        chunk_size: Storlek p√• varje chunk (antal tecken)\n",
    "        overlap: √ñverlappning mellan chunks (antal tecken)\n",
    "    \n",
    "    Returns:\n",
    "        Lista med chunks\n",
    "    \"\"\"\n",
    "    chunks = []\n",
    "    for i in range(0, len(text), chunk_size - overlap):\n",
    "        chunks.append(text[i:i + chunk_size])\n",
    "    return chunks\n",
    "\n",
    "# Skapa chunks\n",
    "chunks = create_chunks(text, chunk_size=1000, overlap=200)\n",
    "print(f\"Antal chunks skapade: {len(chunks)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d6f8f7c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F√∂rsta chunk:\n",
      "L√ÑR DIG AI FR√ÖN\n",
      "GRUNDEN - TILL√ÑMPAD\n",
      "MASKININL√ÑRNING MED\n",
      "PYTHON\n",
      "Antonio Prgomet\n",
      "Terese Johnson\n",
      "Amanda Solberg\n",
      "Linus Rundberg StreuliDetta verk √§r skyddat av upphovsr√§ttslagen.\n",
      "Den som bryter mot upphovsr√§ttslagen kan √•talas av allm√§n √•klagare och d√∂mas till b√∂-\n",
      "ter eller f√§ngelse i upp till tv√• √•r samt bli skyldig att erl√§gga ers√§ttning till upphovsman\n",
      "eller r√§ttsinnehavare.\n",
      "¬© Pedagogicus PublishingInneh√•llsf√∂rteckning\n",
      "F√∂rord 7\n",
      "Bokens hemsida . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 7\n",
      "Bokens m√•lgrupp . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 7\n",
      "Element i boken . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 7\n",
      "Spr√•k . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 8\n",
      "Bokens uppl√§gg . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 8\n",
      "Lycka till . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 9\n",
      "I Introduktion till maskininl√§rning 11\n",
      "1 Intro\n"
     ]
    }
   ],
   "source": [
    "# Visa f√∂rsta chunken\n",
    "print(\"F√∂rsta chunk:\")\n",
    "print(chunks[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90e3ce29",
   "metadata": {},
   "source": [
    "## 5. Embeddings - Konvertera text till vektorer\n",
    "\n",
    "Embeddings representerar text som numeriska vektorer. Semantiskt lika texter f√•r n√§rliggande vektorer.\n",
    "Se kapitel 10 i kursboken f√∂r mer information."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "df9dce20",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skapar embeddings f√∂r 555 chunks i 6 batches...\n",
      "  Batch 1/6... "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úì\n",
      "  Batch 2/6... ‚úì\n",
      "  Batch 3/6... ‚úì\n",
      "  Batch 4/6... ‚úì\n",
      "  Batch 5/6... ‚úì\n",
      "  Batch 6/6... ‚úì\n",
      "\n",
      "‚úì Alla embeddings skapade!\n",
      "Antal embeddings skapade: 555\n",
      "Storlek p√• varje embedding: 768\n"
     ]
    }
   ],
   "source": [
    "from google.genai import types\n",
    "import time\n",
    "\n",
    "def create_embeddings(text_list, model=\"text-embedding-004\", batch_size=100):\n",
    "    \"\"\"\n",
    "    Skapa embeddings f√∂r en lista av texter (med batch-processing).\n",
    "    \n",
    "    Args:\n",
    "        text_list: Lista av texter eller en enskild text\n",
    "        model: Embedding-modell att anv√§nda\n",
    "        batch_size: Antal texter per batch (standar API-gr√§ns: 100)\n",
    "    \n",
    "    Returns:\n",
    "        Lista av embedding-vektorer\n",
    "    \"\"\"\n",
    "    if isinstance(text_list, str):\n",
    "        text_list = [text_list]\n",
    "    \n",
    "    all_embeddings = []\n",
    "    total_batches = (len(text_list) + batch_size - 1) // batch_size\n",
    "    \n",
    "    print(f\"Skapar embeddings f√∂r {len(text_list)} chunks i {total_batches} batches...\")\n",
    "    \n",
    "    for batch_idx in range(0, len(text_list), batch_size):\n",
    "        batch = text_list[batch_idx:batch_idx + batch_size]\n",
    "        current_batch_num = (batch_idx // batch_size) + 1\n",
    "        \n",
    "        try:\n",
    "            print(f\"  Batch {current_batch_num}/{total_batches}...\", end=\" \", flush=True)\n",
    "            \n",
    "            response = client.models.embed_content(\n",
    "                model=model,\n",
    "                contents=batch,\n",
    "                config=types.EmbedContentConfig(task_type=\"SEMANTIC_SIMILARITY\")\n",
    "            )\n",
    "            \n",
    "            for emb in response.embeddings:\n",
    "                all_embeddings.append(emb.values)\n",
    "            \n",
    "            print(\"‚úì\")\n",
    "            \n",
    "            # Liten paus mellan batches f√∂r att undvika rate limiting\n",
    "            if current_batch_num < total_batches:\n",
    "                time.sleep(0.5)\n",
    "                \n",
    "        except Exception as e:\n",
    "            print(f\"‚ùå Fel i batch {current_batch_num}: {e}\")\n",
    "            raise\n",
    "    \n",
    "    print(f\"\\n‚úì Alla embeddings skapade!\")\n",
    "    return all_embeddings\n",
    "\n",
    "# Skapa embeddings f√∂r alla chunks\n",
    "embeddings_list = create_embeddings(chunks, batch_size=100)\n",
    "\n",
    "print(f\"Antal embeddings skapade: {len(embeddings_list)}\")\n",
    "print(f\"Storlek p√• varje embedding: {len(embeddings_list[0])}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "59315145",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F√∂rsta embedding (f√∂rsta 10 v√§rden):\n",
      "[-0.09116102, 0.03508013, -0.038605068, 0.03724536, 0.07020524, -8.3170125e-05, -0.013250188, 0.01706417, 0.039274067, -0.019324668]\n"
     ]
    }
   ],
   "source": [
    "# Visa f√∂rsta 10 v√§rden fr√•n f√∂rsta embeddings-vektorn\n",
    "print(f\"F√∂rsta embedding (f√∂rsta 10 v√§rden):\")\n",
    "print(embeddings_list[0][0:10])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6302d166",
   "metadata": {},
   "source": [
    "## 6. Semantisk s√∂kning - Cosine Similarity\n",
    "\n",
    "Vi anv√§nder cosinuslikhet f√∂r att m√§ta hur lik en anv√§ndarfr√•ga √§r j√§mf√∂rt med varje chunk."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d42c2ae3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skapar embeddings f√∂r 1 chunks i 1 batches...\n",
      "  Batch 1/1... ‚úì\n",
      "\n",
      "‚úì Alla embeddings skapade!\n",
      "Unexpected exception formatting exception. Falling back to standard exception\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\SebbePwnYou\\anaconda3\\Lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3699, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"C:\\Users\\SebbePwnYou\\AppData\\Local\\Temp\\ipykernel_168\\4070036183.py\", line 43, in <module>\n",
      "    relevant_chunks = semantic_search(test_query, chunks, embeddings_list, k=3)\n",
      "                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\SebbePwnYou\\AppData\\Local\\Temp\\ipykernel_168\\4070036183.py\", line 26, in semantic_search\n",
      "    query_embedding = query_embedding_response.embeddings[0].values\n",
      "                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "AttributeError: 'list' object has no attribute 'embeddings'\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\SebbePwnYou\\anaconda3\\Lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2194, in showtraceback\n",
      "    stb = self.InteractiveTB.structured_traceback(\n",
      "          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\SebbePwnYou\\anaconda3\\Lib\\site-packages\\IPython\\core\\ultratb.py\", line 1188, in structured_traceback\n",
      "    return FormattedTB.structured_traceback(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\SebbePwnYou\\anaconda3\\Lib\\site-packages\\IPython\\core\\ultratb.py\", line 1059, in structured_traceback\n",
      "    return VerboseTB.structured_traceback(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\SebbePwnYou\\anaconda3\\Lib\\site-packages\\IPython\\core\\ultratb.py\", line 867, in structured_traceback\n",
      "    formatted_exceptions: list[list[str]] = self.format_exception_as_a_whole(\n",
      "                                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\SebbePwnYou\\anaconda3\\Lib\\site-packages\\IPython\\core\\ultratb.py\", line 779, in format_exception_as_a_whole\n",
      "    frames.append(self.format_record(record))\n",
      "                  ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\SebbePwnYou\\anaconda3\\Lib\\site-packages\\IPython\\core\\ultratb.py\", line 655, in format_record\n",
      "    frame_info.lines,\n",
      "    ^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\SebbePwnYou\\anaconda3\\Lib\\site-packages\\IPython\\core\\tbtools.py\", line 355, in lines\n",
      "    return self._sd.lines  # type: ignore[misc]\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\SebbePwnYou\\anaconda3\\Lib\\site-packages\\stack_data\\utils.py\", line 145, in cached_property_wrapper\n",
      "    value = obj.__dict__[self.func.__name__] = self.func(obj)\n",
      "                                               ^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\SebbePwnYou\\anaconda3\\Lib\\site-packages\\stack_data\\core.py\", line 734, in lines\n",
      "    pieces = self.included_pieces\n",
      "             ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\SebbePwnYou\\anaconda3\\Lib\\site-packages\\stack_data\\utils.py\", line 145, in cached_property_wrapper\n",
      "    value = obj.__dict__[self.func.__name__] = self.func(obj)\n",
      "                                               ^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\SebbePwnYou\\anaconda3\\Lib\\site-packages\\stack_data\\core.py\", line 677, in included_pieces\n",
      "    scope_pieces = self.scope_pieces\n",
      "                   ^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\SebbePwnYou\\anaconda3\\Lib\\site-packages\\stack_data\\utils.py\", line 145, in cached_property_wrapper\n",
      "    value = obj.__dict__[self.func.__name__] = self.func(obj)\n",
      "                                               ^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\SebbePwnYou\\anaconda3\\Lib\\site-packages\\stack_data\\core.py\", line 614, in scope_pieces\n",
      "    scope_start, scope_end = self.source.line_range(self.scope)\n",
      "                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\SebbePwnYou\\anaconda3\\Lib\\site-packages\\stack_data\\core.py\", line 178, in line_range\n",
      "    return line_range(self.asttext(), node)\n",
      "                      ^^^^^^^^^^^^\n",
      "AttributeError: 'Source' object has no attribute 'asttext'\n"
     ]
    }
   ],
   "source": [
    "def cosine_similarity(vec1, vec2):\n",
    "    \"\"\"\n",
    "    Ber√§kna cosinuslikhet mellan tv√• vektorer.\n",
    "    V√§rde mellan -1 och 1, d√§r 1 betyder identisk riktning.\n",
    "    \n",
    "    S√§krare version som hanterar edge cases.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        dot_product = np.dot(vec1, vec2)\n",
    "        norm_vec1 = np.linalg.norm(vec1)\n",
    "        norm_vec2 = np.linalg.norm(vec2)\n",
    "        \n",
    "        # Undvik division med noll\n",
    "        if norm_vec1 == 0 or norm_vec2 == 0:\n",
    "            return 0.0\n",
    "        \n",
    "        return float(dot_product / (norm_vec1 * norm_vec2))\n",
    "    except Exception as e:\n",
    "        print(f\"Fel vid cosinusber√§kning: {e}\")\n",
    "        return 0.0\n",
    "\n",
    "def semantic_search(query, chunks, embeddings_list, k=5):\n",
    "    \"\"\"\n",
    "    S√∂k efter de k mest relevanta chunks f√∂r en given fr√•ga.\n",
    "    \n",
    "    Args:\n",
    "        query: Anv√§ndarens fr√•ga\n",
    "        chunks: Lista av textchunks\n",
    "        embeddings_list: Lista av embedding-vektorer\n",
    "        k: Antal toppta chunks att returnera\n",
    "    \n",
    "    Returns:\n",
    "        Lista med de k mest relevanta chunks\n",
    "    \"\"\"\n",
    "    print(f\"üîç S√∂ker efter relevanta delar f√∂r: '{query}'\")\n",
    "    \n",
    "    try:\n",
    "        # Skapa embedding f√∂r fr√•gan\n",
    "        print(\"  - Genererar fr√•geembedding...\", end=\" \", flush=True)\n",
    "        query_embeddings = create_embeddings(query, batch_size=1)\n",
    "        query_embedding = query_embeddings[0]\n",
    "        print(\"‚úì\")\n",
    "        \n",
    "        # Ber√§kna likhet mellan fr√•ga och alla chunks\n",
    "        print(f\"  - J√§mf√∂r med {len(embeddings_list)} chunks...\", end=\" \", flush=True)\n",
    "        similarity_scores = []\n",
    "        \n",
    "        for i, chunk_embedding in enumerate(embeddings_list):\n",
    "            similarity_score = cosine_similarity(query_embedding, chunk_embedding)\n",
    "            similarity_scores.append((i, similarity_score))\n",
    "        \n",
    "        print(\"‚úì\")\n",
    "        \n",
    "        # Sortera efter likhet (h√∂gst f√∂rst)\n",
    "        similarity_scores.sort(key=lambda x: x[1], reverse=True)\n",
    "        \n",
    "        # Returnera top k chunks\n",
    "        top_indices = [index for index, score in similarity_scores[:k]]\n",
    "        top_scores = [score for index, score in similarity_scores[:k]]\n",
    "        \n",
    "        print(f\"  - Hittade {len(top_indices)} relevanta chunks\")\n",
    "        for idx, (chunk_idx, score) in enumerate(zip(top_indices, top_scores), 1):\n",
    "            print(f\"    {idx}. Likhet: {score:.3f}\")\n",
    "        \n",
    "        result_chunks = [chunks[index] for index in top_indices]\n",
    "        return result_chunks\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Fel i semantisk s√∂kning: {e}\")\n",
    "        raise\n",
    "\n",
    "# Testa semantisk s√∂kning\n",
    "print(\"Testar semantisk s√∂kning...\\n\")\n",
    "test_query = \"Vad √§r maskininl√§rning?\"\n",
    "try:\n",
    "    relevant_chunks = semantic_search(test_query, chunks, embeddings_list, k=3)\n",
    "    print(f\"\\n‚úì F√∂rsta relevanta chunk (f√∂rsta 300 tecken):\\n{relevant_chunks[0][:300]}...\")\n",
    "except Exception as e:\n",
    "    print(f\"Kunde inte genomf√∂ra s√∂kning: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80b41887",
   "metadata": {},
   "source": [
    "## 7. RAG - Generera svar med kontext\n",
    "\n",
    "Nu kombinerar vi retrieval (s√∂kning) med generation (svar) f√∂r att skapa en chattbot."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "9849c261",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RAG-funktioner √§r klara!\n"
     ]
    }
   ],
   "source": [
    "# Systemmeddelande f√∂r chattbotten\n",
    "system_prompt = \"\"\"Du √§r en hj√§lpsam AI-assistent som svarar p√• fr√•gor baserat ENDAST p√• \n",
    "den kontexten som tillhandah√•lls. Du √§r en expert p√• boken 'L√§r dig AI fr√•n grunden - Till√§mpad \n",
    "maskininl√§rning med Python'.\n",
    "\n",
    "Instruktioner:\n",
    "1. Svara ENDAST baserat p√• kontexten som ges\n",
    "2. Om det inte finns tillr√§cklig information i kontexten, s√§g: \"Det vet jag inte baserat p√• dokumentet\"\n",
    "3. F√∂rs√∂k INTE att gissa eller l√§gga till information utanf√∂r kontexten\n",
    "4. Formulera dig enkelt och dela upp svaret i stycken\n",
    "5. Citera relevanta delar fr√•n dokumentet n√§r l√§mpligt\"\"\"\n",
    "\n",
    "def generate_user_prompt(query, context_chunks):\n",
    "    \"\"\"\n",
    "    Skapa ett anv√§ndarmeddelande med fr√•ga och kontext.\n",
    "    \"\"\"\n",
    "    context = \"\\n\\n---\\n\\n\".join(context_chunks)\n",
    "    user_prompt = f\"\"\"Baserat p√• f√∂ljande kontext fr√•n dokumentet, svara p√• denna fr√•ga:\n",
    "\n",
    "KONTEXT:\n",
    "{context}\n",
    "\n",
    "FR√ÖGA: {query}\n",
    "\n",
    "SVAR:\"\"\"\n",
    "    return user_prompt\n",
    "\n",
    "def generate_response(query, model=model, k=5):\n",
    "    \"\"\"\n",
    "    Generera ett svar p√• en fr√•ga med RAG.\n",
    "    \n",
    "    Args:\n",
    "        query: Anv√§ndarens fr√•ga\n",
    "        model: LLM-modell att anv√§nda\n",
    "        k: Antal chunks att anv√§nda som kontext\n",
    "    \n",
    "    Returns:\n",
    "        Svar fr√•n modellen\n",
    "    \"\"\"\n",
    "    # H√§mta relevanta chunks\n",
    "    context_chunks = semantic_search(query, chunks, embeddings_list, k=k)\n",
    "    \n",
    "    # Skapa prompt\n",
    "    user_message = generate_user_prompt(query, context_chunks)\n",
    "    \n",
    "    # Generera svar\n",
    "    response = client.models.generate_content(\n",
    "        model=model,\n",
    "        config=genai.types.GenerateContentConfig(\n",
    "            system_instruction=system_prompt\n",
    "        ),\n",
    "        contents=user_message\n",
    "    )\n",
    "    return response.text\n",
    "\n",
    "print(\"RAG-funktioner √§r klara!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cce9fd38",
   "metadata": {},
   "source": [
    "## 8. Testa chattbotten\n",
    "\n",
    "Testa med n√•gra exempelfr√•gor relaterade till boken."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "439c5cdf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "FR√ÖGA: Vad √§r prompt engineering?\n",
      "============================================================\n",
      "Prompt engineering handlar om att st√§lla \"effektiva fr√•gor\" till chattbottar f√∂r att f√• \"b√§ttre\" svar. Som tumregel √§r det bra att vara s√• specifik, deskriptiv och detaljerad som m√∂jligt om √∂nskad kontext, utfall, l√§ngd, format och stil.\n"
     ]
    }
   ],
   "source": [
    "# Testa fr√•ga 1\n",
    "fr√•ga1 = \"Vad √§r prompt engineering?\"\n",
    "print(f\"\\n{'='*60}\")\n",
    "print(f\"FR√ÖGA: {fr√•ga1}\")\n",
    "print(f\"{'='*60}\")\n",
    "svar1 = generate_response(fr√•ga1, k=3)\n",
    "print(svar1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "a79cebcb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "FR√ÖGA: Vad √§r RAG?\n",
      "============================================================\n",
      "En RAG-modell inneh√•ller tv√• delar. Den f√∂rsta delen √§r en retriever, som s√∂ker efter relevanta stycken i en st√∂rre text. Dessa stycken skickas sedan vidare som kontext till den andra delen, en generator som genererar svaren utifr√•n den givna kontexten.\n"
     ]
    }
   ],
   "source": [
    "# Testa fr√•ga 2\n",
    "fr√•ga2 = \"Vad √§r RAG?\"\n",
    "print(f\"\\n{'='*60}\")\n",
    "print(f\"FR√ÖGA: {fr√•ga2}\")\n",
    "print(f\"{'='*60}\")\n",
    "svar2 = generate_response(fr√•ga2, k=3)\n",
    "print(svar2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "68d28502",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "FR√ÖGA: Vad √§r Chunking?\n",
      "============================================================\n",
      "Chunking kan g√∂ras utan h√§nsyn till inneh√•llet i texten, vilket kan leda till f√∂rlust av information och s√§mre semantiska s√∂kningar.\n",
      "\n",
      "Semantic chunking √§r en metod f√∂r att dela upp text i mindre delar baserat p√• den semantiska betydelsen och inneb√§r att skapa delar som inneh√•ller meningar som ligger n√§ra varandra i betydelse. Metoden innefattar sentence-based chunking, f√∂ljt av skapandet av embeddings av meningarna och en semantisk s√∂kning f√∂r att j√§mf√∂ra deras inneh√•ll. Resultaten anv√§nds sedan f√∂r att skapa chunks som inneh√•ller meningar som √§r semantiskt relaterade.\n"
     ]
    }
   ],
   "source": [
    "# Testa fr√•ga 3\n",
    "fr√•ga3 = \"Vad √§r Chunking?\"\n",
    "print(f\"\\n{'='*60}\")\n",
    "print(f\"FR√ÖGA: {fr√•ga3}\")\n",
    "print(f\"{'='*60}\")\n",
    "svar3 = generate_response(fr√•ga3, k=3)\n",
    "print(svar3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "50dc0e2f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "FR√ÖGA: Vad √§r favoritkolorerna p√• stj√§rnorna?\n",
      "============================================================\n",
      "Det vet jag inte baserat p√• dokumentet.\n"
     ]
    }
   ],
   "source": [
    "# Testa en fr√•ga som inte √§r relaterad till dokumentet\n",
    "fr√•ga4 = \"Vad √§r favoritkolorerna p√• stj√§rnorna?\"\n",
    "print(f\"\\n{'='*60}\")\n",
    "print(f\"FR√ÖGA: {fr√•ga4}\")\n",
    "print(f\"{'='*60}\")\n",
    "svar4 = generate_response(fr√•ga4, k=3)\n",
    "print(svar4)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b961698",
   "metadata": {},
   "source": [
    "## 9. Interaktiv chattbot\n",
    "\n",
    "En enkel interaktiv chattbot d√§r du kan st√§lla egna fr√•gor. Skriv \"quit\" f√∂r att avsluta."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d190dcc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "INTERAKTIV CHATTBOT - Baserad p√• 'L√§r dig AI fr√•n grunden'\n",
      "============================================================\n",
      "St√§ll en fr√•ga och chattbotten svarar baserat p√• boken.\n",
      "Skriv 'quit' eller 'exit' f√∂r att sluta.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"ENKLA TESTFR√ÖGOR - Visa/d√∂lj svar nedan\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# F√∂rdefinierade testfr√•gor\n",
    "test_questions = [\n",
    "    \"Vad √§r maskininl√§rning?\",\n",
    "    \"Vilka √§r huvudtyperna av maskininl√§rning?\",\n",
    "    \"Vad √§r Python?\",\n",
    "    \"Vad √§r supervised learning?\",\n",
    "    \"Vad √§r unsupervised learning?\",\n",
    "]\n",
    "\n",
    "# St√§ll dina egna fr√•gor genom att √§ndra denna lista:\n",
    "user_questions = [\n",
    "    \"Vad √§r Deep Learning?\",\n",
    "    \"N√§mn n√•gra popul√§ra Python-bibliotek f√∂r ML\",\n",
    "]\n",
    "\n",
    "all_questions = test_questions + user_questions\n",
    "\n",
    "print(f\"\\nK√∂rs {len(all_questions)} testfr√•gor...\\n\")\n",
    "\n",
    "results = []\n",
    "for idx, question in enumerate(all_questions, 1):\n",
    "    print(f\"[{idx}/{len(all_questions)}] Fr√•ga: {question}\")\n",
    "    try:\n",
    "        answer = generate_response(question, k=3)\n",
    "        results.append({\"question\": question, \"answer\": answer})\n",
    "        print(f\"Svar: {answer[:200]}...\\n\")\n",
    "    except Exception as e:\n",
    "        print(f\"Fel: {e}\\n\")\n",
    "\n",
    "print(\"=\"*60)\n",
    "print(f\"‚úì Alla {len(results)} fr√•gor √§r klara!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5629aa2",
   "metadata": {},
   "source": [
    "## 10. Evaluering av chattbotten (Bonus)\n",
    "\n",
    "Vi kan evaluera kvaliteten p√• svaren genom att j√§mf√∂ra med ideala svar."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "108da010",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test-dataset laddat med 2 testfr√•gor.\n",
      "{'question': 'Vad √§r supervised learning?', 'ideal_answer': 'Supervised learning √§r en typ av maskininl√§rning d√§r modellen tr√§nas p√• m√§rkta exempel.'}\n"
     ]
    }
   ],
   "source": [
    "# Testdata f√∂r evaluering\n",
    "test_data = [\n",
    "    {\n",
    "        \"question\": \"Vad √§r supervised learning?\",\n",
    "        \"ideal_answer\": \"Supervised learning √§r en typ av maskininl√§rning d√§r modellen tr√§nas p√• m√§rkta exempel.\"\n",
    "    },\n",
    "    {\n",
    "        \"question\": \"N√§mn tv√• popul√§ra Python-bibliotek f√∂r maskininl√§rning.\",\n",
    "        \"ideal_answer\": \"TensorFlow och scikit-learn √§r tv√• popul√§ra Python-bibliotek f√∂r maskininl√§rning.\"\n",
    "    }\n",
    "]\n",
    "\n",
    "print(\"Test-dataset laddat med 2 testfr√•gor.\")\n",
    "print(test_data[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "727de9a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unexpected exception formatting exception. Falling back to standard exception\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\SebbePwnYou\\anaconda3\\Lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3699, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"C:\\Users\\SebbePwnYou\\AppData\\Local\\Temp\\ipykernel_168\\3682832112.py\", line 32, in <module>\n",
      "    ai_answer = generate_response(test_question, k=3)\n",
      "                ^^^^^^^^^^^^^^^^^\n",
      "NameError: name 'generate_response' is not defined. Did you mean: 'evaluate_response'?\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\SebbePwnYou\\anaconda3\\Lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2194, in showtraceback\n",
      "    stb = self.InteractiveTB.structured_traceback(\n",
      "          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\SebbePwnYou\\anaconda3\\Lib\\site-packages\\IPython\\core\\ultratb.py\", line 1188, in structured_traceback\n",
      "    return FormattedTB.structured_traceback(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\SebbePwnYou\\anaconda3\\Lib\\site-packages\\IPython\\core\\ultratb.py\", line 1059, in structured_traceback\n",
      "    return VerboseTB.structured_traceback(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\SebbePwnYou\\anaconda3\\Lib\\site-packages\\IPython\\core\\ultratb.py\", line 867, in structured_traceback\n",
      "    formatted_exceptions: list[list[str]] = self.format_exception_as_a_whole(\n",
      "                                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\SebbePwnYou\\anaconda3\\Lib\\site-packages\\IPython\\core\\ultratb.py\", line 779, in format_exception_as_a_whole\n",
      "    frames.append(self.format_record(record))\n",
      "                  ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\SebbePwnYou\\anaconda3\\Lib\\site-packages\\IPython\\core\\ultratb.py\", line 655, in format_record\n",
      "    frame_info.lines,\n",
      "    ^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\SebbePwnYou\\anaconda3\\Lib\\site-packages\\IPython\\core\\tbtools.py\", line 355, in lines\n",
      "    return self._sd.lines  # type: ignore[misc]\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\SebbePwnYou\\anaconda3\\Lib\\site-packages\\stack_data\\utils.py\", line 145, in cached_property_wrapper\n",
      "    value = obj.__dict__[self.func.__name__] = self.func(obj)\n",
      "                                               ^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\SebbePwnYou\\anaconda3\\Lib\\site-packages\\stack_data\\core.py\", line 734, in lines\n",
      "    pieces = self.included_pieces\n",
      "             ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\SebbePwnYou\\anaconda3\\Lib\\site-packages\\stack_data\\utils.py\", line 145, in cached_property_wrapper\n",
      "    value = obj.__dict__[self.func.__name__] = self.func(obj)\n",
      "                                               ^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\SebbePwnYou\\anaconda3\\Lib\\site-packages\\stack_data\\core.py\", line 677, in included_pieces\n",
      "    scope_pieces = self.scope_pieces\n",
      "                   ^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\SebbePwnYou\\anaconda3\\Lib\\site-packages\\stack_data\\utils.py\", line 145, in cached_property_wrapper\n",
      "    value = obj.__dict__[self.func.__name__] = self.func(obj)\n",
      "                                               ^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\SebbePwnYou\\anaconda3\\Lib\\site-packages\\stack_data\\core.py\", line 614, in scope_pieces\n",
      "    scope_start, scope_end = self.source.line_range(self.scope)\n",
      "                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\SebbePwnYou\\anaconda3\\Lib\\site-packages\\stack_data\\core.py\", line 178, in line_range\n",
      "    return line_range(self.asttext(), node)\n",
      "                      ^^^^^^^^^^^^\n",
      "AttributeError: 'Source' object has no attribute 'asttext'\n"
     ]
    }
   ],
   "source": [
    "# Systemmeddelande f√∂r evaluering\n",
    "evaluation_system_prompt = \"\"\"Du √§r ett intelligentakterar som utv√§rderar svar fr√•n en AI-assistent.\n",
    "Bed√∂m svaret enligt f√∂ljande skala:\n",
    "- 1.0: Svaret √§r mycket bra och n√§ra det ideala svaret\n",
    "- 0.5: Svaret √§r delvis korrekt men saknar detaljer\n",
    "- 0.0: Svaret √§r felaktigt eller inte relaterat\n",
    "\n",
    "Ge ett tal mellan 0 och 1 tillsammans med en kort f√∂rklaring.\"\"\"\n",
    "\n",
    "def evaluate_response(question, ai_answer, ideal_answer):\n",
    "    \"\"\"\n",
    "    Evaluera ett svar fr√•n chattbotten.\n",
    "    \"\"\"\n",
    "    evaluation_prompt = f\"\"\"Fr√•ga: {question}\n",
    "AI-assistentens svar: {ai_answer}\n",
    "Idealiskt svar: {ideal_answer}\n",
    "\n",
    "Utv√§rdera AI-svaret:\"\"\"\n",
    "    \n",
    "    response = client.models.generate_content(\n",
    "        model=model,\n",
    "        config=genai.types.GenerateContentConfig(\n",
    "            system_instruction=evaluation_system_prompt\n",
    "        ),\n",
    "        contents=evaluation_prompt\n",
    "    )\n",
    "    return response.text\n",
    "\n",
    "# Evaluera f√∂rsta testfr√•ga\n",
    "test_question = test_data[0][\"question\"]\n",
    "ideal_answer = test_data[0][\"ideal_answer\"]\n",
    "ai_answer = generate_response(test_question, k=3)\n",
    "\n",
    "print(f\"\\nF√ÖGA: {test_question}\")\n",
    "print(f\"\\nAI-SVAR:\\n{ai_answer}\")\n",
    "print(f\"\\nIDEALT SVAR:\\n{ideal_answer}\")\n",
    "print(f\"\\nEVALUERING:\\n{evaluate_response(test_question, ai_answer, ideal_answer)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6df8d5db",
   "metadata": {},
   "source": [
    "## Sammanfattning\n",
    "\n",
    "Du har nu skapat en fullst√§ndig RAG-baserad chattbot som:\n",
    "\n",
    "1. **L√§ser PDF-dokument** - Extraherar text fr√•n PDF-filer\n",
    "2. **Chunkar text** - Delar upp text i hanterbar storlek\n",
    "3. **Skapar embeddings** - Konverterar text till vektorer\n",
    "4. **S√∂ker semantiskt** - Hittar relevanta delar baserat p√• likhet\n",
    "5. **Genererar svar** - Anv√§nder LLM f√∂r att skapa sammanh√§ngande svar\n",
    "6. **Evaluerar resultat** - Bed√∂mer kvaliteten p√• svaren\n",
    "\n",
    "### Vidare f√∂rdjupning:\n",
    "- Utforska LangChain: https://academy.langchain.com/\n",
    "- L√§r dig om olika embedding-modeller\n",
    "- Experimentera med olika chunk-storlekar\n",
    "- Implementera minneshantering f√∂r flerturs-konversationer"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
