{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f494a615",
   "metadata": {},
   "source": [
    "# CIFAR-100 Uppgift - CNN, KerasTuner och Transfer Learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8da588fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importera bibliotek\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "\n",
    "from tensorflow.keras.datasets import cifar100\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.models import Sequential, Model\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dropout, Dense, GlobalAveragePooling2D\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.applications import VGG16, ResNet50\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "\n",
    "import keras_tuner as kt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d73a7815",
   "metadata": {},
   "source": [
    "## 1. Ladda och Förbereda Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b67c4b67",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ladda CIFAR-100 dataset\n",
    "(x_train, y_train), (x_test, y_test) = cifar100.load_data()\n",
    "\n",
    "# Visa dimensioner\n",
    "print(f\"Training data shape: {x_train.shape}\")\n",
    "print(f\"Training labels shape: {y_train.shape}\")\n",
    "print(f\"Test data shape: {x_test.shape}\")\n",
    "print(f\"Test labels shape: {y_test.shape}\")\n",
    "print(f\"Number of classes: {len(np.unique(y_train))}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ed25366",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalisera pixelvärdena till [0, 1]\n",
    "x_train_normalized = x_train.astype('float32') / 255.0\n",
    "x_test_normalized = x_test.astype('float32') / 255.0\n",
    "\n",
    "# One-hot encoding av labels\n",
    "y_train_categorical = to_categorical(y_train, 100)\n",
    "y_test_categorical = to_categorical(y_test, 100)\n",
    "\n",
    "print(f\"Normalized training data shape: {x_train_normalized.shape}\")\n",
    "print(f\"One-hot encoded labels shape: {y_train_categorical.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ab42ceb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualisera några exempel från datasetet\n",
    "plt.figure(figsize=(12, 12))\n",
    "for i in range(25):\n",
    "    plt.subplot(5, 5, i + 1)\n",
    "    plt.imshow(x_train[i])\n",
    "    plt.title(f\"Class: {y_train[i][0]}\")\n",
    "    plt.axis('off')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e14c67ca",
   "metadata": {},
   "source": [
    "## 2. Del a) Baseline CNN-modell\n",
    "\n",
    "Skapa en grundläggande CNN-modell för att prediktera CIFAR-100 datasetet."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34df665c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_baseline_cnn():\n",
    "    \"\"\"Skapa en baseline CNN-modell\"\"\"\n",
    "    model = Sequential([\n",
    "        Conv2D(32, kernel_size=(3, 3), padding='same', activation='relu', input_shape=(32, 32, 3)),\n",
    "        MaxPooling2D(pool_size=(2, 2)),\n",
    "        \n",
    "        Conv2D(64, kernel_size=(3, 3), padding='same', activation='relu'),\n",
    "        MaxPooling2D(pool_size=(2, 2)),\n",
    "        \n",
    "        Conv2D(128, kernel_size=(3, 3), padding='same', activation='relu'),\n",
    "        MaxPooling2D(pool_size=(2, 2)),\n",
    "        \n",
    "        Flatten(),\n",
    "        Dropout(0.5),\n",
    "        Dense(256, activation='relu'),\n",
    "        Dropout(0.5),\n",
    "        Dense(100, activation='softmax')\n",
    "    ])\n",
    "    \n",
    "    model.compile(\n",
    "        optimizer='adam',\n",
    "        loss='categorical_crossentropy',\n",
    "        metrics=['accuracy']\n",
    "    )\n",
    "    \n",
    "    return model\n",
    "\n",
    "# Skapa modellen\n",
    "baseline_model = create_baseline_cnn()\n",
    "baseline_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4487663",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Träna baseline-modellen\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True)\n",
    "\n",
    "history_baseline = baseline_model.fit(\n",
    "    x_train_normalized, y_train_categorical,\n",
    "    epochs=30,\n",
    "    batch_size=64,\n",
    "    validation_split=0.2,\n",
    "    callbacks=[early_stopping],\n",
    "    verbose=1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d78a84df",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Utvärdera baseline-modellen\n",
    "baseline_loss, baseline_accuracy = baseline_model.evaluate(x_test_normalized, y_test_categorical, verbose=0)\n",
    "print(f\"\\n=== BASELINE CNN RESULTAT ===\")\n",
    "print(f\"Test Accuracy: {baseline_accuracy:.4f}\")\n",
    "print(f\"Test Loss: {baseline_loss:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57c388cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualisera träningshistorik för baseline\n",
    "plt.figure(figsize=(12, 4))\n",
    "\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(history_baseline.history['accuracy'], label='Training Accuracy')\n",
    "plt.plot(history_baseline.history['val_accuracy'], label='Validation Accuracy')\n",
    "plt.title('Baseline CNN - Accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(history_baseline.history['loss'], label='Training Loss')\n",
    "plt.plot(history_baseline.history['val_loss'], label='Validation Loss')\n",
    "plt.title('Baseline CNN - Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7bf50b6",
   "metadata": {},
   "source": [
    "## 3. Del b) Hyperparameter-tuning med KerasTuner\n",
    "\n",
    "Använd KerasTuner för att hitta optimala hyperparametrar."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a7ca763",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_tuner_model(hp):\n",
    "    \"\"\"Bygg modell med tuningsbara hyperparametrar\"\"\"\n",
    "    model = Sequential()\n",
    "    \n",
    "    # Första Conv-layer\n",
    "    model.add(Conv2D(\n",
    "        filters=hp.Int('conv_1_filters', min_value=32, max_value=128, step=32),\n",
    "        kernel_size=(3, 3),\n",
    "        padding='same',\n",
    "        activation='relu',\n",
    "        input_shape=(32, 32, 3)\n",
    "    ))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    \n",
    "    # Andra Conv-layer\n",
    "    model.add(Conv2D(\n",
    "        filters=hp.Int('conv_2_filters', min_value=64, max_value=256, step=64),\n",
    "        kernel_size=(3, 3),\n",
    "        padding='same',\n",
    "        activation='relu'\n",
    "    ))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    \n",
    "    # Tredje Conv-layer\n",
    "    model.add(Conv2D(\n",
    "        filters=hp.Int('conv_3_filters', min_value=128, max_value=512, step=128),\n",
    "        kernel_size=(3, 3),\n",
    "        padding='same',\n",
    "        activation='relu'\n",
    "    ))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    \n",
    "    model.add(Flatten())\n",
    "    \n",
    "    # Dropout rate\n",
    "    model.add(Dropout(hp.Float('dropout_1', min_value=0.3, max_value=0.7, step=0.1)))\n",
    "    \n",
    "    # Dense layer\n",
    "    model.add(Dense(\n",
    "        units=hp.Int('dense_units', min_value=128, max_value=512, step=128),\n",
    "        activation='relu'\n",
    "    ))\n",
    "    model.add(Dropout(hp.Float('dropout_2', min_value=0.3, max_value=0.7, step=0.1)))\n",
    "    \n",
    "    model.add(Dense(100, activation='softmax'))\n",
    "    \n",
    "    # Learning rate tuning\n",
    "    learning_rate = hp.Choice('learning_rate', values=[1e-2, 1e-3, 1e-4])\n",
    "    \n",
    "    model.compile(\n",
    "        optimizer=Adam(learning_rate=learning_rate),\n",
    "        loss='categorical_crossentropy',\n",
    "        metrics=['accuracy']\n",
    "    )\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4c731b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Skapa en tuner (RandomSearch)\n",
    "tuner = kt.RandomSearch(\n",
    "    build_tuner_model,\n",
    "    objective='val_accuracy',\n",
    "    max_trials=10,  # Öka för bättre resultat (tar längre tid)\n",
    "    executions_per_trial=1,\n",
    "    directory='keras_tuner_dir',\n",
    "    project_name='cifar100_tuning'\n",
    ")\n",
    "\n",
    "print(tuner.search_space_summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19d66588",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Kör sökningen efter bästa hyperparametrar\n",
    "early_stopping_tuner = EarlyStopping(monitor='val_loss', patience=3, restore_best_weights=True)\n",
    "\n",
    "tuner.search(\n",
    "    x_train_normalized, y_train_categorical,\n",
    "    epochs=20,\n",
    "    batch_size=64,\n",
    "    validation_split=0.2,\n",
    "    callbacks=[early_stopping_tuner],\n",
    "    verbose=1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3099f98",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hämta bästa modellen\n",
    "best_model = tuner.get_best_models(num_models=1)[0]\n",
    "best_hyperparameters = tuner.get_best_hyperparameters(num_trials=1)[0]\n",
    "\n",
    "print(\"\\n=== BÄSTA HYPERPARAMETRAR ===\")\n",
    "print(f\"Conv Layer 1 Filters: {best_hyperparameters.get('conv_1_filters')}\")\n",
    "print(f\"Conv Layer 2 Filters: {best_hyperparameters.get('conv_2_filters')}\")\n",
    "print(f\"Conv Layer 3 Filters: {best_hyperparameters.get('conv_3_filters')}\")\n",
    "print(f\"Dense Units: {best_hyperparameters.get('dense_units')}\")\n",
    "print(f\"Dropout 1: {best_hyperparameters.get('dropout_1')}\")\n",
    "print(f\"Dropout 2: {best_hyperparameters.get('dropout_2')}\")\n",
    "print(f\"Learning Rate: {best_hyperparameters.get('learning_rate')}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e8a6c6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Utvärdera den tunade modellen\n",
    "tuned_loss, tuned_accuracy = best_model.evaluate(x_test_normalized, y_test_categorical, verbose=0)\n",
    "print(f\"\\n=== KERASTUNER RESULTAT ===\")\n",
    "print(f\"Test Accuracy: {tuned_accuracy:.4f}\")\n",
    "print(f\"Test Loss: {tuned_loss:.4f}\")\n",
    "print(f\"\\nFörbättring jämfört med baseline: {(tuned_accuracy - baseline_accuracy):.4f} ({(tuned_accuracy - baseline_accuracy)/baseline_accuracy*100:.2f}%)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36654544",
   "metadata": {},
   "source": [
    "## 4. Del c) Transfer Learning\n",
    "\n",
    "Använd en förtränad modell (t.ex. VGG16 eller ResNet50) för att förbättra resultaten."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b515c22",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Förbereda data för transfer learning (vissa modeller kräver större bilder)\n",
    "# Vi behåller 32x32 för CIFAR-100, men vissa modeller fungerar bättre med större storlekar\n",
    "\n",
    "def create_transfer_learning_model(base_model_name='VGG16'):\n",
    "    \"\"\"Skapa transfer learning modell\"\"\"\n",
    "    \n",
    "    # Ladda förtränad modell utan top layers\n",
    "    if base_model_name == 'VGG16':\n",
    "        base_model = VGG16(\n",
    "            weights='imagenet',\n",
    "            include_top=False,\n",
    "            input_shape=(32, 32, 3)\n",
    "        )\n",
    "    elif base_model_name == 'ResNet50':\n",
    "        base_model = ResNet50(\n",
    "            weights='imagenet',\n",
    "            include_top=False,\n",
    "            input_shape=(32, 32, 3)\n",
    "        )\n",
    "    \n",
    "    # Frys alla lager i base model\n",
    "    base_model.trainable = False\n",
    "    \n",
    "    # Bygg den kompletta modellen\n",
    "    model = Sequential([\n",
    "        base_model,\n",
    "        GlobalAveragePooling2D(),\n",
    "        Dense(512, activation='relu'),\n",
    "        Dropout(0.5),\n",
    "        Dense(256, activation='relu'),\n",
    "        Dropout(0.5),\n",
    "        Dense(100, activation='softmax')\n",
    "    ])\n",
    "    \n",
    "    model.compile(\n",
    "        optimizer=Adam(learning_rate=0.001),\n",
    "        loss='categorical_crossentropy',\n",
    "        metrics=['accuracy']\n",
    "    )\n",
    "    \n",
    "    return model\n",
    "\n",
    "# Skapa transfer learning modell\n",
    "transfer_model = create_transfer_learning_model('VGG16')\n",
    "transfer_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "095c6f8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Träna transfer learning modellen\n",
    "early_stopping_transfer = EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True)\n",
    "\n",
    "history_transfer = transfer_model.fit(\n",
    "    x_train_normalized, y_train_categorical,\n",
    "    epochs=30,\n",
    "    batch_size=64,\n",
    "    validation_split=0.2,\n",
    "    callbacks=[early_stopping_transfer],\n",
    "    verbose=1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14c0dc6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Utvärdera transfer learning modellen\n",
    "transfer_loss, transfer_accuracy = transfer_model.evaluate(x_test_normalized, y_test_categorical, verbose=0)\n",
    "print(f\"\\n=== TRANSFER LEARNING RESULTAT ===\")\n",
    "print(f\"Test Accuracy: {transfer_accuracy:.4f}\")\n",
    "print(f\"Test Loss: {transfer_loss:.4f}\")\n",
    "print(f\"\\nFörbättring jämfört med baseline: {(transfer_accuracy - baseline_accuracy):.4f} ({(transfer_accuracy - baseline_accuracy)/baseline_accuracy*100:.2f}%)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efcdea49",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualisera träningshistorik för transfer learning\n",
    "plt.figure(figsize=(12, 4))\n",
    "\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(history_transfer.history['accuracy'], label='Training Accuracy')\n",
    "plt.plot(history_transfer.history['val_accuracy'], label='Validation Accuracy')\n",
    "plt.title('Transfer Learning - Accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(history_transfer.history['loss'], label='Training Loss')\n",
    "plt.plot(history_transfer.history['val_loss'], label='Validation Loss')\n",
    "plt.title('Transfer Learning - Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b70d3b9",
   "metadata": {},
   "source": [
    "## 5. Jämförelse av Resultat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d1611a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sammanställning av resultat\n",
    "results = {\n",
    "    'Metod': ['Baseline CNN', 'KerasTuner', 'Transfer Learning'],\n",
    "    'Test Accuracy': [baseline_accuracy, tuned_accuracy, transfer_accuracy],\n",
    "    'Test Loss': [baseline_loss, tuned_loss, transfer_loss]\n",
    "}\n",
    "\n",
    "import pandas as pd\n",
    "results_df = pd.DataFrame(results)\n",
    "results_df['Accuracy (%)'] = results_df['Test Accuracy'] * 100\n",
    "print(\"\\n=== SAMMANSTÄLLNING AV RESULTAT ===\")\n",
    "print(results_df.to_string(index=False))\n",
    "print(f\"\\nBästa metod: {results_df.loc[results_df['Test Accuracy'].idxmax(), 'Metod']}\")\n",
    "print(f\"Högsta Accuracy: {results_df['Test Accuracy'].max():.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d00ce3dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualisera jämförelse\n",
    "plt.figure(figsize=(10, 6))\n",
    "methods = ['Baseline CNN', 'KerasTuner', 'Transfer Learning']\n",
    "accuracies = [baseline_accuracy, tuned_accuracy, transfer_accuracy]\n",
    "\n",
    "bars = plt.bar(methods, accuracies, color=['#1f77b4', '#ff7f0e', '#2ca02c'])\n",
    "plt.ylabel('Test Accuracy')\n",
    "plt.title('Jämförelse av Modell-prestanda på CIFAR-100')\n",
    "plt.ylim([0, 1])\n",
    "\n",
    "# Lägg till värden på toppen av varje stapel\n",
    "for bar in bars:\n",
    "    height = bar.get_height()\n",
    "    plt.text(bar.get_x() + bar.get_width()/2., height,\n",
    "             f'{height:.4f}',\n",
    "             ha='center', va='bottom')\n",
    "\n",
    "plt.grid(axis='y', alpha=0.3)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "032e0a39",
   "metadata": {},
   "source": [
    "## 6. Slutsatser\n",
    "### Svar på uppgifterna:\n",
    "**a) Baseline CNN-modell:**\n",
    "- Skapade en grundläggande CNN med flera konvolutionella lager\n",
    "- Modellen fungerar som utgångspunkt för jämförelse\n",
    "\n",
    "**b) Hyperparameter-tuning med KerasTuner:**\n",
    "- Använde RandomSearch för att hitta optimala hyperparametrar\n",
    "- Justerade antal filter, dense units, dropout rates och learning rate\n",
    "- Resultat: [Jämför med baseline för att se om det blev bättre]\n",
    "\n",
    "**c) Transfer Learning:**\n",
    "- Använde förtränad VGG16 från ImageNet\n",
    "- Frös base model och tränade endast de nya lagren\n",
    "- Resultat: [Jämför med baseline och KerasTuner]"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
