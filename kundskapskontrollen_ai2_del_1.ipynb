{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "42727cf8",
   "metadata": {},
   "source": [
    "### Kapitel 1 - Introduktion till maskininlärning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8427ed0e",
   "metadata": {},
   "source": [
    "# 1. Hur hänger AI, ML och DL ihop?\n",
    "AI, ML, DL:\n",
    "AI är breda tekniker för att göra system “intelligenta”.\n",
    "ML är en AI-gren där modeller lärs från data.\n",
    "DL är en ML-underdel som använder djupa neuronnät för komplexa uppgifter."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "961b60e5",
   "metadata": {},
   "source": [
    "# 2. Vilka är de fyra problemkategorierna inom ML?\n",
    "Klassificering, regression, klustring, rekommendation/associationsanalys"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5faec552",
   "metadata": {},
   "source": [
    "# 3. Förklara följande:\n",
    "a) Vad är syftet med att dela upp data i träningsdata, valideringsdata och\n",
    "testdata?\n",
    "# Träning passar modellen, validering justerar hyperparametrar och tidig stoppning, test ger opartisk uppskattning \n",
    "\n",
    "b) Vad är k-delad korsvalidering för något?\n",
    "# Dela datan i k lika foldar; träna på k-1, validera på 1, rotera och medelvärdesbilda resultat för robustare skattning.\n",
    "\n",
    "c) Vad är root mean squared error (RMSE) för något?\n",
    "# Roten ur medelvärdet av kvadrerade fel: RMSE = Straffar stora fel extra och mäts i samma enhet som målet.\n",
    "\n",
    "d) Vad är en hyperparameter för något? Vad är en parameter för något?\n",
    "# Hyperparametrar styr inlärningsprocessen (t.ex. antal träd, regulariseringsstyrka); parametrar är modellens lärda vikter.\n",
    "\n",
    "e) Vad är grid search och hur hänger namnet “grid” och “search” ihop med\n",
    "processen som genomförs? Läser vi dokumentationen: https://scikit-learn.\n",
    "org/stable/modules/generated/sklearn.model_selection.GridSearchCV så\n",
    "ser vi att hyperparametern refit har standardvärdet True, vad innebär\n",
    "det?\n",
    "# Grid search provar alla kombinationer av hyperparametrar i ett rutnät (“grid”), utvärderar (“search”) och väljer bästa. refit=True betyder att modellen tränas om på hela träningsdatan med de bästa hyperparametrarna så att vi kan använda best_estimator_.\n",
    "\n",
    "f) Vad är kategorisk data och hur hanteras det? I ditt svar, använd begreppen\n",
    "nominal data, ordinal data, one-hot-encoding, dummy-variable-encoding\n",
    "och ordinal encoding.\n",
    "# Nominal (ingen ordning, t.ex. färg)\n",
    "# one-hot-encoding eller dummy-variable-encoding (en kolumn kan droppas för att undvika full kollinearitet). Ordinal (naturlig ordning, t.ex. “låg/medel/hög”\n",
    "# ordinal encoding som mappar till rangtal.\n",
    "# (Rangtal = sätt att ordna data, från lägst till högst (eller tvärtom), där det minsta värdet får rang 1, näst minst 2, och så vidare.)\n",
    "\n",
    "g) Vad är feature engineering för något?\n",
    "# Skapa eller göra om variabler för att förbättra modeller.\n",
    "\n",
    "h) Vad menas med principle of parsimony?\n",
    "# Välj enklaste modell som förklarar datan tillräckligt väl.. undvik onödig komplexitet"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c4a9088",
   "metadata": {},
   "source": [
    "# 4. Vad menas med att “en modell är en förenkling av verkligheten”?\n",
    "Den tar bort många detaljer i verkligheten och fångar bara mönster som finns i tillgänglig data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e808406a",
   "metadata": {},
   "source": [
    "# 5. Vad menas med att en modell är “överanpassad” eller overfitted på engelska?\n",
    "Presterar sämre på ny data, hög träff på träning, låg på test."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81b9907d",
   "metadata": {},
   "source": [
    "# 6. Högre är bättre i scikit-learn scoring, vad innebär det?\n",
    "Scorer är definierade så att större värde betyder bättre. För felmått används ofta negativa värden (neg RMSE) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d48b14b",
   "metadata": {},
   "source": [
    "# 7. Vad är tvärsnittsdata, tidsseriedata och paneldata? Exemplifiera när respektive datakategori kan uppstå.\n",
    "Tvärsnittsdata flera enheter vid en tidpunkt (elpriser under år 2025).\n",
    "Tidsseriedata en enhet över tid (dagliga bilpriser). \n",
    "Paneldata flera enheter över tid (kvartalsvisa försäljningssiffror per butik)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24ab6036",
   "metadata": {},
   "source": [
    "# 8. Ge några exempel på verkliga tillämpningsområden inom ML. Sök gärna på nätet för att besvara frågan.\n",
    "Hälso- och sjukvård: bilddiagnostik (t.ex. cancerdetektion), triagering och riskprediktion för återinläggning.\n",
    "Finansiella tjänster: kreditbedömning, bedrägeriidentifiering, algoritmisk handel och kundbortfallsprognoser.\n",
    "Transport och logistik: ruttoptimering, ETA-prognoser, efterfrågeprognoser och autonom körning.\n",
    "Handel/marknadsföring: rekommendationssystem, dynamisk prissättning och lageroptimering."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce1b2216",
   "metadata": {},
   "source": [
    "# 9. Generellt sett gäller det att högre är bättre i scikit-learn scoring, därför används exempelvis scoring='neg_mean_squared_error'. Förklara logiken bakom detta, det vill säga att vi använder “negative” mean squared error.\n",
    "scikit-learns scorer-konvention är att “större värde är bättre”. Felmått som MSE blir då inverterade till negativa tal så att lägre fel motsvarar högre (mindre negativt) score.\n",
    "Exempel: två modeller med MSE 4 och 9 får scorer -4 och -9; -4 > -9, alltså väljs modellen med lägre MSE."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73b8b6c4",
   "metadata": {},
   "source": [
    "### Kapitel 2 - Ett ML projekt från början till slut"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3138615c",
   "metadata": {},
   "source": [
    "# 1. checklista med sju steg. Beskriv de sju stegen översiktligt. I verkligheten, följs dessa steg i en rak progression eller arbetar man generellt sett mer iterativt?\n",
    "1) Problemformulering och mål. \n",
    "2) Datainsamling. \n",
    "3) Dataförberedelse (rensning, hantering av saknade värden, kodning, skalning). \n",
    "4) Explorativ analys och feature engineering. \n",
    "5) Modellval och träning (inkl. hyperparametertuning). \n",
    "6) Utvärdering/validering. \n",
    "7) Deployment/övervakning. Loopar tillbaka när insikter eller driftkrav kräver justeringar."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0bc7171a",
   "metadata": {},
   "source": [
    "# 2. Vad menas med att en modell produktionssätts?\n",
    "Att modellen görs tillgänglig i en driftmiljö där den kan användas av riktiga användare eller system (API, batchjobb, app), med rutiner för skalning, säkerhet, övervakning och uppdatering.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad3f975c",
   "metadata": {},
   "source": [
    "\n",
    "# 3. Vad är scikit-learn för något? Biblioteket följer några centrala designprinciper. Vilka är dessa? Vad är estimators, predictors och transformers?\n",
    "scikit-learn är ett Pythonbibliotek för ML med enhetligt API. Designprinciper: konsekvent API (`fit`, `transform`, `predict`), kompositionsbarhet (pipelines), rimliga standarder (sane defaults), tydlig separation mellan hyperparametrar och lärda parametrar, samt verktyg för validering och sök (CV, grid/random search). Estimators: objekt som kan `fit` data. Predictors: estimators med `predict`/`predict_proba`. Transformers: estimators med `transform`/`fit_transform` som ändrar features."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1885a2e",
   "metadata": {},
   "source": [
    "\n",
    "# 4. Vad är TensorFlow och Keras?\n",
    "TensorFlow är ett ramverk för numeriska beräkningar och djupinlärning med stöd för CPU/GPU/TPU och deployment (serving, mobile, edge). Keras är ett högre API-lager ovanpå TensorFlow (default) för att bygga och träna neuronnät enklare, sekventiellt eller funktionellt."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9fa8698c",
   "metadata": {},
   "source": [
    "# 5. Kalle och Stina diskuterar maskininlärning över en lunch. Kalle säger “om jag tränat en modell och den inte presterar bra nog på testdatan så justerar jag den tills den gör det.” Stina säger “det är ett stort fel att göra så, det enda du då åstadkommer är att du överanpassar testdatan. Hela syftet med testdatan försvinner då”. Vad säger du om deras dialog?\n",
    "Testdatan ska vara helt oberoende tills alla modell- och hyperparameterbeslut är klara. Att iterera mot testresultat gör att testet slutar vara en opartisk generaliseringskoll. Man riskerar \"overfitt\" till just det testsetet. Man ska i stället använda valideringsdata eller korsvalidering för justeringar, och spara testsetet till absolut sist.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98a19366",
   "metadata": {},
   "source": [
    "# 6. Många AI/ML-projekt uppnår inte målen eller lämnar aldrig prototypstadiet. Vad beror det på och hur bör vi förhålla oss?\n",
    "Vanliga orsaker: otydligt eller rörligt mål, bristande eller dålig data, felvalda mätetal.\n",
    "\n",
    "Förhållningssätt: lås mål och mätetal tidigt, gör datakvalitetsarbete först och håll produktägare löpande."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b39a9345",
   "metadata": {},
   "source": [
    "### Kapitel 3 - Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7702b073",
   "metadata": {},
   "source": [
    "# 1. Vad kännetecknar regressionsproblem? Ge några exempel på tillämpningsområden.\n",
    "Regression förutsäger ett kontinuerligt numeriskt värde (inte kategorier). Exempel: bosprisförutsägelse (baserat på storlek, läge), elprisförutsägelse, temperaturbortfall, börskursförutsägelse, leveranstidsprognos, hälsoriskpoäng."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c1b4c88",
   "metadata": {},
   "source": [
    "# 2. Förklara utvärderingsmåtten RMSE, MSE och MAE.\n",
    "MSE (Mean Squared Error): medelvärde av kvadrerade fel, $\\text{MSE} = \\frac{1}{n}\\sum(y_i - \\hat{y}_i)^2$. Straffar stora avvikelser extra.\n",
    "\n",
    "RMSE (Root Mean Squared Error): roten ur MSE, $\\text{RMSE} = \\sqrt{\\text{MSE}}$. Samma enhet som målvariabel, tolkbart.\n",
    "\n",
    "MAE (Mean Absolute Error): medelvärde av absoluta fel, $\\text{MAE} = \\frac{1}{n}\\sum|y_i - \\hat{y}_i|$. Robust mot extremvärden, linjär bestrafning."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "257e7e3c",
   "metadata": {},
   "source": [
    "# 3. Om vi ska rangordna olika modeller, spelar det någon roll om RMSE eller MSE används? Varför?\n",
    "Nej, det spelar ingen roll. Eftersom $\\text{RMSE} = \\sqrt{\\text{MSE}}$ och kvadratroten är en monoton stegvis växande funktion, rangordningen av modeller förblir densamma. Den modell med lägst MSE har också lägst RMSE."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83410f35",
   "metadata": {},
   "source": [
    "# 4. Förklara mycket översiktligt vad gradient descent är.\n",
    "Gradient descent är en optimeringsalgoritm som minimerar en förlustfunktion genom att gradvis uppdatera modellens parametrar i riktningen motsatt gradienten (brantaste nedstigningen). Startar från slumpmässiga parametrar och justerar iterativt för att nå ett lägre värde på förlusten."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f6b6e5d",
   "metadata": {},
   "source": [
    "# 5. Vad är the bias variance trade-off? Varför är mer komplexa modeller inte alltid bättre?\n",
    "Bias är felet från att anta ett för förenklat samband; variance är känsligheten för små variationer i träningsdata. Enkla modeller har högt bias (kan inte fånga mönstret) men lågt variance. Komplexa modeller har lågt bias men högt variance (overfit). Totalt test-fel = bias² + variance + irreducible error. En alltför komplex modell kan lära brus istället för mönster, och presterar sämre på ny data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fcb17f51",
   "metadata": {},
   "source": [
    "# 6. Några vanligt förekommande modeller för regressionsproblem är enligt nedan. Förklara översiktligt hur respektive modell fungerar.\n",
    "\n",
    "a) Linjär regression: anpassar en linjär funktion $y = \\beta_0 + \\beta_1 x_1 + ... + \\beta_p x_p$ till data genom att minimera summan av kvadrerade residualer. Enkel, tolkbar, antar linjärt samband.\n",
    "\n",
    "b) Ridge regression: linjär regression med L2-regularisering (kvadrerad norm av koefficienter läggs till förlusten). Krymper stora koefficienter för att minska variance och hantera multikollinearitet.\n",
    "\n",
    "c) Lasso regression: linjär regression med L1-regularisering (absolut norm). Kan sätta vissa koefficienter exakt till noll, vilket ger automatisk feature selection.\n",
    "\n",
    "d) Elastic net: kombinerar L1 och L2-regularisering (Ridge + Lasso). Balanserar båda regulariseringsfördelarna.\n",
    "\n",
    "e) Support Vector Machines (SVR): hittar en hyperplan som minimerar fel inom en $\\epsilon$-marginal, med möjlighet för kärnor (kernels) för icke-linjär regression. Robust, fungerar bra i höga dimensioner.\n",
    "\n",
    "f) Beslutsträd (Decision Trees): rekursiv uppdelning av feature-utrymmet i rektangulära områden. Enkla, icke-linjära, tolka bara, men lätta att overfitta.\n",
    "\n",
    "g) Ensemble learning (Voting, Bagging): kombinerar flera modeller (voting tar medelvärde av prediktioner). Minskar variance och kan förbättra generalisering.\n",
    "\n",
    "h) Random Forest: ensemble av besluttträd tränade på slumpmässiga delmängder av data och features. Robust, höga dimensioner, reducerar overfit genom ensemble."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2dd322ef",
   "metadata": {},
   "source": [
    "# 7. Vad menas med white box modeller och black box modeller?\n",
    "White box: modeller vars beslut är tolka bara och förklara bara. \n",
    "\n",
    "Black box: modeller som är svåra eller omöjliga att förklara intuitivt. Valet mellan dem beror på krav på tolkbarhet vs prestanda."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef8df572",
   "metadata": {},
   "source": [
    "# 8. Vad är skillnaden mellan bagging och pasting?\n",
    "Bagging: träna flera modeller på slumpmässiga delmängder av träningsdata DÖM BORTFATTNING.\n",
    "Minskar variance genom diversitet och nästa möjlighet för träning på samma sampel flera gånger.\n",
    "\n",
    "Pasting: träna flera modeller på slumpmässiga delmängder ÖGA UTAN ÅTERLÄGGNING.\n",
    "Mindre diversitet men snabbare beräkning; båda är ensemble-metoder som använder voting/medelvärde för slutlig prediktion."
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
